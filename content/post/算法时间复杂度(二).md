---
title: "算法时间复杂度（二）"
date: 2021-11-01
draft: false
summary: "算法时间复杂度（二）"
---

这篇文章讲解：递归算法的时间复杂度(recursive algorithm time complexity)、最好情况时间复杂度(best case time complexity)、最坏情况时间复杂度(worst case time complexity)、平均时间复杂度(average case time complexity)和均摊时间复杂度(amortized  time complexity)

# 递归算法的时间复杂度

如果递归函数中，只进行一次递归调用，递归深度为depth

在每个递归的函数中，时间复杂度为T

则总体的时间复杂度为O(T * depth)

在前面的学习中，归并排序与快速排序都带有递归的意思，并且时间复杂度都是O(nlogn),但并不是有递归的函数就一定是O(nlogn)级别的。从以下两种情况进行分析。

## 1、递归中进行一次递归调用的复杂度分析

二分查找法

int binarySearch(int arr[], int l, int r, int target) {
  if (l > r) return -1

  int mid = l + (r - 1) / 2
  if (arr[mid] === target) return mid
  else if (arr[mid] > target)
  return binarySearch(arr, l, mid - 1, target)
  else 
  return binarySearch(arr, mid + 1, target)
}

比如在这段二分查找法的代码中，每次在[l, r]范围中去查找目标的位置，如果中间的元素arr[min]不是target，那么判断arr[mid]是比target大还是小，进而再次调用binarySearch这个函数

在这个递归函数中，每一次没有找到target时，那么调用左边的binarySearch函数，要么调用右边的binarySearch函数，也就是说在此次递归中，最多调用了一次递归调用而已。根据数学知识，需要log2n次才能递归到底。因此，二分查找法的时间复杂度为O(logn)

求和

  int sum(int n) {
    if (n == 0) return 0
    return n + sum(n - 1)
  }

在这段代码中比较容易理解理解递归深度随输入n的增加而线性递增，因此时间复杂度为O(n)

求幂

  // 递归深度：logn
  // 时间复杂度：O(logn)
  double pow(double x, int n) {
    if (n == 0) return 1.0

    double t = pow(x, n / 2)
    if (n % 2) return x * t * t
    return t * t
  }

递归深度为logn，因为是求需要除以2多少次才能到底。

## 2、递归中进行多次递归调用的复杂度分析

递归算法中比较难计算的事多次递归调用

先看下面这段代码，有两次递归调用。

  // O(2^n)指数级别的数量级，后续动态规划的优化点
  int f(int n) {
    if (n == 0) return 1
    return f(n - 1) + f(n - 1)
  }

递归树中节点数就是diamante计算的调用次数

比如当n=3时，调用次数计算公式为

  1 + 2 + 4 + 8 = 15

一般的，调用次数计算公式为

  2^0 + 2^1 + 2^2 + …… + 2^n
  = 2^(n+1) - 1
  = O(2^n)

与之有所类似的是 归并排序 的递归树，区别点在于

  1、上述例子的树的深度为n，而 归并排序 的递归树深度为logn
  2、上述例子中每次处理的数据规模是一样的，而在归并排序中每个节点处理的数据规模是逐渐缩小的 

因此，在如 归并排序 等排序算法中，每一层处理的数据量为O(n)级别，同时有logn层，时间复杂度便是O(nlogn)

# 最好、最坏情况时间复杂度

最好、最坏情况时间复杂度指的是特殊情况下的时间复杂度。

动图表明的是在数组array中寻找变量x第一次出现的位置，若没有找到，则返回-1；否则返回位置下标。

  int find(int [] array, int n, int x) {
    for (int i = 0; i < n; i++) {
      if (array[i] == x) {
        return i
        break
      }
    }
    return -1
  }

在这里当数组中第一个元素就是要找的x时，时间复杂度是O(1)，而当最后一个元素才是x时，时间复杂度是O(n)

最好情况时间复杂度就是在最理想情况下执行代码的时间复杂度，它的时间是最短的；最坏情况时间复杂度就是在最糟糕情况下执行代码的时间复杂度，它的时间是最长的。

# 平均情况时间复杂度

最好、最坏时间复杂度就是在极端条件下的复杂度，发生的概率不大，不能代表平均水平。那么为了更好的表示平均情况下的算法复杂度，就需要引入平均情况时间复杂度。

平均情况时间复杂度可用代码在所有可能情况下执行次数的加权平均值表示。

还是以find函数为例，从概率的角度来看，x在数组中每一个位置的可能性都是相同的，为1/n。那么平均情况时间复杂度就可以用下面的方式计算：

    ((1 + 2 + ... + n) / n + n ) / 2 = (3n + 1) / 4

find函数的平均时间复杂度为O(n)

#  均摊复杂度分析

我们通过一个动态数组的push_back操作来理解均摊复杂度。

template <typename T>
class MyVector {
  private:
    T* data;
    int size;          // 存储数组中的元素个数
    int capacity;      // 存储数组中可以容纳的最大的元素个数
    // 复杂度为O(n)
    void resize(int newCapacity) {
      T *newData = new T[newCapacity];
      for (int i = 0; i < size; i++) {
        newData[i] = data[i]
      }
      data = newData
      capacity = newCapacity
    }
    
  public: 
    MyVector() {
      data = new T[100]
      size = 0
      capacity = 100
    }
    // 平均复杂度为O(1)
    void push_back(T e) {
      if (size == capacity) {
        resize(2 * capacity)
        data[size++] = e
      }
    }
    // 平均复杂度为O(1)
    T pop_back() {
      size --;
      return data[size]
    }
}

push_back实现的功能是往数组的末尾添加一个元素，如果数组没有满，直接往后面插入元素；如果数组满了，即size == capacity，则将数组扩容一倍，然后再插入元素

例如，数组长度为n，则前n次调用push_back复杂度都为O(1)级别；在第n+1次则需要先进行n次元素转移操作，然后再进行1次插入操作，复杂度为O(n)

因此，平均来看：对于容量为n的动态数组，前面添加元素需要消耗了1*n的时间，扩容操作消耗n时间，总共就是2*n的时间，因此均摊时间复杂度为O(2n/n)=O(2)，也就是O(1)级别了。

可以得出一个比较有意思的结论：一个相对比较耗时的操作，如果能保证它不会每次都被触发，那么这个相对比较耗时的操作，它所相应的时间是可以分摊到其他的操作中来的。